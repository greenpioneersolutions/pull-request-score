# pull-request-score

1â€¯â€¯Why focus on Pullâ€‘Requests?
Independent studies of ~1â€¯million PRs highlight review waitâ€‘time as the #1 bottleneck in cycle time (â€‘4â€¯days on average before the first pickup). Teams that keep review turnaround underâ€¯â‰¤12â€¯h rank among the industryâ€™s â€œeliteâ€ performers. 
linearb.io

Commercial analytics platforms (LinearB, Code Climate Velocity, Pluralsightâ€¯Flow, Haystack, Swarmia, Waydev, etc.) all anchor their productivity dashboards on PR signals such as cycle time, review depth, and merge success rate. 
linearb.io
docs.velocity.codeclimate.com
docs.velocity.codeclimate.com
docs.velocity.codeclimate.com

2â€¯â€¯What the GitHub APIs already expose
Capability	GraphQLâ€¯v4	RESTâ€¯v3	Notes
Pull Request metadata (author, state, labels, draft flag, merge base, mergeable)	PullRequest object fields (e.g., state, isDraft, mergedAt, mergeable) 
docs.github.com
GET /repos/{owner}/{repo}/pulls	GraphQL lets you request everything in one roundâ€‘trip, keeping rateâ€‘limit cost low.
Reviews & approvals	reviews(first:100){ state author createdAt }	GET /pulls/{num}/reviews	Needed for firstâ€‘review latency, reviewer count, approval cadence.
Review & issue comments	comments connection	GET /issues/{num}/comments	Enables â€œdiscussion densityâ€ metric.
Commits & diff stats	commits{ commit{ committedDate } }, additions, deletions, changedFiles	GET /pulls/{num}/commits, .../files	Needed for PR size, churn and followâ€‘up pushes.
Checks / CI	commits{ commit{ statusCheckRollup } }	GET /repos/{owner}/{repo}/commits/{sha}/check-runs	Lets you calculate passâ€‘rate and flakyâ€‘failure rate.
Timeline events	timelineItems connection	GET /issues/{num}/timeline (preview)	Surfaces â€œreview requestedâ€, â€œready for reviewâ€, â€œautoâ€‘merge enabledâ€, etc.

Enterprise parity â€“ All endpoints above exist on GitHub Enterpriseâ€¯Serverâ€¯â‰¥â€¯3.13 
docs.github.com
. Only the base URL changes.

3â€¯â€¯Metric catalogue (baseline + stretch)
3.1â€¯Speed
Metric	Definition	Insight
PRâ€¯Cycleâ€¯Time	mergedAtâ€¯â€“â€¯createdAt	Endâ€‘toâ€‘end delivery speed.
Pickupâ€¯Time	firstReviewAtâ€¯â€“â€¯createdAt	How fast reviewers react.
Reviewâ€¯Turnaround	mergedAtâ€¯â€“â€¯firstApprovalAt	Latency after signâ€‘off.
Idleâ€¯Spans	Total time PR spent with no commits and no reviews.	Hidden queues.

3.2â€¯Collaboration
Metric	Definition
Reviewerâ€¯Count	Unique review authors per PR.
Crossâ€‘teamâ€¯Reviewâ€¯Rate	% reviews from outside authorâ€™s team (requires mapping file).
Commentâ€¯Density	(issueCommentsâ€¯+â€¯reviewComments)â€¯/â€¯changedFiles.

3.3â€¯Quality / Risk
Metric	Definition
Sizeâ€¯Buckets	S,â€¯M,â€¯L based on LOC Î” (thresholds configurable).
Iterativeâ€¯Rework	# of additional pushes after first review.
Changeâ€‘Requestâ€¯Ratio	# reviewsÂ state==CHANGES_REQUESTEDâ€¯/â€¯total reviews.
Successâ€¯Rate	mergedPRsâ€¯/â€¯(closedâ€¯+â€¯merged) 
docs.velocity.codeclimate.com
Revertâ€¯Rate	% merges reverted within 48â€¯h (requires commitâ€‘graph scan).

3.4â€¯Workflow / CI
Metric	Definition
CIâ€¯Passâ€¯Rate	successful workflowsâ€¯/â€¯total runs on PR branch.
Repeatedâ€¯Failures	Median # reruns to reach green.

All formulas will be implemented as pure functions so your team can derive or weight them any way you like.

4â€¯â€¯Existing tooling landscape &â€¯gaps
Tool	Licence	Strengths	Limitations (for our purpose)
GitHub â€œInsightsâ€ (builtâ€‘in)	Native	basic PR graphs	no programmatic export
Apacheâ€¯DevLake 
github.com
devlake.apache.org
Apacheâ€‘2.0	full ETL + dashboards, DORA bundles	heavy DB footprint; ðŸ‘·â€â™‚â€¯not a light NPM lib
LinearB	SaaS	automatic team heuristics	closed source; cost per dev
Code Climate Velocity	SaaS	review depth, risk flags	closed source; coarse API
gitinspector / gitâ€‘quickâ€‘stats	MIT	commitâ€‘level, CLI	no PR coverage
Augur, GrimoireLab	Apacheâ€‘2.0	rich community metrics	steep learning curve

Opportunity: a lightweight, embeddable TypeScript SDK that yields just the numbers, ready for BI pipes (Looker, Powerâ€¯BI) or Slack bots, without forcing a storage backend.

5â€¯â€¯Package architecture proposal
pgsql
Copy
@gh-pr-metrics/
â”œâ”€ src/
â”‚  â”œâ”€ api/
â”‚  â”‚   â”œâ”€ githubGraphql.ts   // thin Octokit wrapper
â”‚  â”‚   â””â”€ rateLimiter.ts     // @octokit/plugin-throttling
â”‚  â”œâ”€ collectors/
â”‚  â”‚   â””â”€ pullRequests.ts    // pagination, ETag caching
â”‚  â”œâ”€ calculators/
â”‚  â”‚   â”œâ”€ cycleTime.ts
â”‚  â”‚   â”œâ”€ reviewMetrics.ts
â”‚  â”‚   â””â”€ ciMetrics.ts
â”‚  â”œâ”€ models/                // TS types â†” GitHub schema
â”‚  â”œâ”€ output/
â”‚  â”‚   â””â”€ writers.ts         // JSON, CSV, stdout
â”‚  â””â”€ cli.ts                 // `gh-pr-metrics --repo octo/hello`
â”œâ”€ test/ (Jest)
â”œâ”€ .github/workflows/ci.yml  // lint, unit tests, semanticâ€‘release
â””â”€ package.json              // ESM, Nodeâ€¯18, strict TS
Core design principles
GraphQLâ€‘first â€“ single batched query minimizes rateâ€‘limit cost. 
docs.github.com

Stateless by default â€“ metrics are calculated inâ€‘memory; adapters for SQLite/Redis can be added later.

Plugin interface â€“ each metric = MetricPlugin { slug, description, calculate(pr) }, enabling enterprise users to add proprietary KPIs.

Dual interface â€“ importable API and zeroâ€‘config CLI.

Enterprise support â€“ GITHUB_BASE_URL env variable routes to onâ€‘prem servers; PAT or GitHub App JWT supported.

Type safety â€“ autoâ€‘generated GraphQL typings via @octokit/graphql-schema ensures compileâ€‘time safety.

Security â€“ token never written to disk; optional --no-cache flag for airâ€‘gapped environments.

6â€¯â€¯Example usage
ts
Copy
import { analyzeRepository } from '@gh-pr-metrics/core';

const metrics = await analyzeRepository({
  owner: 'acme-inc',
  repo: 'payments-api',
  auth: process.env.GH_TOKEN,         // PAT with `repo` scope
  since: '2024â€‘01â€‘01',                // ISO or daysBack
});

console.log(metrics.summary);
/*
{
  pullRequestCount: 412,
  medianCycleTimeHours: 26.3,
  p95PickupTimeHours: 9.1,
  approvalSaturation: 1.8,
  largePrRatio: 0.12,
  successRate: 0.97,
  ...
}
*/
CLI equivalent:

bash
Copy
npx gh-pr-metrics acme-inc/payments-api --since 90d --format csv > metrics.csv
7â€¯â€¯Development roadmap
Sprint	Deliverables
0â€¯(1â€¯wk)	Repo bootstrap, MIT licence, Prettier/ESLint, Octokit core wrapper.
1â€¯(2â€¯wks)	Data collector (GraphQL pagination), JSON output, metrics: cycle time, pickup time, reviewer count.
2â€¯(2â€¯wks)	CI metrics, size buckets, success rate, CSV writer, CLI packaging.
3â€¯(2â€¯wks)	Plugin API, SQLite cache, GitHub App auth, enterprise baseâ€‘URL test matrix.
4â€¯(2â€¯wks)	Documentation site (Docusaurus), sample Looker Studio connector, 1.0.0 release via semanticâ€‘release.
Backlog	GitLab adapter, Bitbucket adapter, Slack summarizer, DORA bundles, Grafana datasource, PR risk scoring ML experiment.

8â€¯â€¯Metric definitions (canonical formulas)
slug	Calculation	Output unit
cycle_time	mergedAt â€“ createdAt	hours
pickup_time	firstReviewSubmittedAt â€“ createdAt	hours
review_iterations	count distinct sets where state==CHANGES_REQUESTED preceding APPROVED	integer
approval_count	reviews where state==APPROVED	integer
comment_density	(issueComments + reviewComments) / changedFiles	ratio
pr_size	additions + deletions	LOC
success_rate	merged / (closed + merged)	percentage
ci_pass_rate	successful check runs / total runs	percentage

(Metrics emitted perâ€‘PR and aggregated by mean/median/p95.)

9â€¯â€¯Comparing to openâ€‘source alternatives
Apache DevLake offers hundreds of metrics and dashboards outâ€‘ofâ€‘box but assumes you will run a Postgres + Grafana stack and ETL nightly. If you only need programmatic numbers, DevLake is overâ€‘kill. 
github.com
devlake.apache.org

Smaller CLI tools (gitâ€‘quickâ€‘stats, gitinspector) ignore the PR workflow entirely; they operate on commit history only.

Your package fills the SDK gap: dropâ€‘in, infraâ€‘light, TypeScriptâ€‘native, embeddable in scripts, CI, or backstage plugins.

10â€¯â€¯Next steps for internal rollout
Pilot â€“ Run the CLI against one highâ€‘traffic repo for the past 90â€¯days; export to CSV and share findings with the team.

Baseline â€“ Agree internally on thresholds (e.g., p50 cycleâ€¯time â‰¤24â€¯h, p95 pickupâ€¯time â‰¤12â€¯h).

Automate â€“ Wire the package into a scheduled GitHub Action that posts weekly summaries to Slack or your BI warehouse.

Refine â€“ Gather feedback; add or drop metrics via the plugin API.

Openâ€‘source launch â€“ Publishâ€¯v1.0 on npm, announce on the GitHub Marketplace, and tag goodâ€‘firstâ€‘issue items to grow community adoption.

Final thought
Metrics should illuminate systemsâ€”not rank individuals. Use these numbers to expose queue time, bottlenecks, and collaboration patterns, then pair them with qualitative insights (retros, code reviews) for a dataâ€‘informed, humanâ€‘centric engineering culture.
